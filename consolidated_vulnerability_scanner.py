import requests
from bs4 import BeautifulSoup
import json
from urllib.parse import urlparse
import datetime

def scrape_website(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  
        soup = BeautifulSoup(response.content, 'html.parser')
        return soup
    except requests.exceptions.RequestException as e:
        print(f"Error: Failed to fetch URL '{url}': {str(e)}")
        return None

def send_request(url, payload, method='POST'):
    try:
        if method == 'POST':
            response = requests.post(url, data=payload)
        elif method == 'GET':
            response = requests.get(url, params=payload)
        response.raise_for_status()  
        return response
    except requests.exceptions.RequestException as e:
        print(f"Error: Failed to send request to '{url}': {str(e)}")
        return None

def detect_sql_injection(url):
    payload = {"input": "' OR '1'='1"}
    response = send_request(url, payload)
    if response and ("SQL syntax" in response.text or "unexpected" in response.text):
        return True
    return False

def detect_stored_xss(url):
    payload = {"input": "<script>alert('Stored XSS')</script>"}
    response = send_request(url, payload)
    if response:
        stored_response = send_request(url, {}, 'GET')
        if stored_response and "<script>alert('Stored XSS')</script>" in stored_response.text:
            return True
    return False

def detect_dom_xss(url):
    payload = {"input": "<script>document.write('DOM XSS')</script>"}
    response = send_request(url, payload)
    if response and "DOM XSS" in response.text:
        return True
    return False

def detect_reflected_xss(url):
    payload = {"input": "<script>alert('Reflected XSS')</script>"}
    response = send_request(url, payload)
    if response and "<script>alert('Reflected XSS')</script>" in response.text:
        return True
    return False

def detect_csrf(url, csrf_token):
    payload = {"input": "data", "csrf_token": csrf_token}
    response = send_request(url, payload)
    if response and ("invalid CSRF token" in response.text):
        return True
    return False

def extract_csrf_token(url):
    try:
        soup = scrape_website(url)
        if soup:
            #Assume that the CSRF token is in a hidden input field as 'csrf_token'
            token = soup.find('input', {'name': 'csrf_token'})
            if token and token['value']:
                return token['value']
        return None
    except Exception as e:
        print(f"Error: Failed to extract CSRF token from '{url}': {str(e)}")
        return None

def generate_report(url, vulnerabilities):
    report_entry = {
        "url": url,
        "vulnerabilities": vulnerabilities,
        "timestamp": datetime.datetime.now().isoformat()
    }
    with open('vulnerability_report.json', 'a') as file:
        json.dump([report_entry], file, indent=4)

def validate_url(url):
    if not url:
        print("Error: Please enter a valid URL.")
        return False
    
    parsed_url = urlparse(url)
    if not parsed_url.scheme or not parsed_url.netloc:
        print(f"Error: Invalid URL format. Please include 'http://' or 'https://' in the URL.")
        return False
    
    try:
        response = requests.get(url)
        response.raise_for_status()
        return True
    except requests.exceptions.RequestException as e:
        print(f"Error: The URL '{url}' is not reachable: {str(e)}")
        return False

def check_post_method_allowed(url):
    try:
        response = requests.options(url)
        if 'POST' in response.headers.get('Allow', ''):
            return True
    except requests.exceptions.RequestException as e:
        print(f"Error: Failed to check methods for URL '{url}': {str(e)}")
    return False

def perform_scan(url):
    if not validate_url(url):
        return "Scan aborted. Invalid or unreachable URL."
    
    if not check_post_method_allowed(url):
        return "Scan aborted. POST method not allowed for this URL."
    
    print(f"Scanning {url}...")

    csrf_token = extract_csrf_token(url)
    if not csrf_token:
        print("Error: Failed to extract CSRF token. Continuing with other tests.")

    vulnerabilities = {
        "sql_injection": detect_sql_injection(url),
        "stored_xss": detect_stored_xss(url),
        "dom_xss": detect_dom_xss(url),
        "reflected_xss": detect_reflected_xss(url),
        "csrf": detect_csrf(url, csrf_token) if csrf_token else "CSRF token extraction failed"
    }
    
    generate_report(url, vulnerabilities)
    return json.dumps(vulnerabilities, indent=4)

if __name__ == "__main__":
    import sys
    url_to_scan = ""
    if len(sys.argv) > 1:
        url_to_scan = sys.argv[1]
    else:
        while not validate_url(url_to_scan):
            url_to_scan = input("Enter the URL to scan: ").strip()
    
    result = perform_scan(url_to_scan)
    print(result)
